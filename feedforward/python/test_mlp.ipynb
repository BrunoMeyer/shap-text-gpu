{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4c9fe00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.4.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/margotte/Mestrado/GPU/shap-text-gpu/.venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/margotte/Mestrado/GPU/shap-text-gpu/.venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/margotte/Mestrado/GPU/shap-text-gpu/.venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/margotte/Mestrado/GPU/shap-text-gpu/.venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/margotte/Mestrado/GPU/shap-text-gpu/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 621, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"/home/margotte/Mestrado/GPU/shap-text-gpu/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 478, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/margotte/Mestrado/GPU/shap-text-gpu/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 372, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/home/margotte/Mestrado/GPU/shap-text-gpu/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 834, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/margotte/Mestrado/GPU/shap-text-gpu/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 464, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/margotte/Mestrado/GPU/shap-text-gpu/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/margotte/Mestrado/GPU/shap-text-gpu/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3123, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/margotte/Mestrado/GPU/shap-text-gpu/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3178, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/margotte/Mestrado/GPU/shap-text-gpu/.venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/margotte/Mestrado/GPU/shap-text-gpu/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/margotte/Mestrado/GPU/shap-text-gpu/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3641, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/margotte/Mestrado/GPU/shap-text-gpu/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3701, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_14276/2908830761.py\", line 3, in <module>\n",
      "    import torch\n",
      "  File \"/home/margotte/Mestrado/GPU/shap-text-gpu/.venv/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/margotte/Mestrado/GPU/shap-text-gpu/.venv/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/margotte/Mestrado/GPU/shap-text-gpu/.venv/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/margotte/Mestrado/GPU/shap-text-gpu/.venv/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/margotte/Mestrado/GPU/shap-text-gpu/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/margotte/Mestrado/GPU/shap-text-gpu/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/margotte/Mestrado/GPU/shap-text-gpu/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Disabling PyTorch because PyTorch >= 2.4 is required but found 2.2.2\n",
      "PyTorch was not found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x76215c5c3ed0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "# reproducibility\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5d39ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters (script defaults)\n",
    "DATASET = \"imdb\"\n",
    "TOKENIZER = \"bert-base-uncased\"\n",
    "MAX_LEN = 64\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LAYERS = 3\n",
    "TRAIN_SAMPLES = 2000\n",
    "TEST_SAMPLES = 256\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Validation / early stopping\n",
    "VAL_RATIO = 0.1\n",
    "PATIENCE = 5\n",
    "# Dropout (applied between layers during training only)\n",
    "DROPOUT_RATE = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5403c47b",
   "metadata": {},
   "source": [
    "# Reproduce default MLP from `train_export.py`\n",
    "This notebook splits parameter definition, imports, dataset prep, tokenization, training, and testing into separate cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ea28728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding-based MLP: word-level embeddings + mean pooling\n",
    "import torchtext\n",
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import vocab as torchtext_vocab\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "class EmbeddingMLP(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embed_dim: int, hidden_dim: int, num_classes: int, padding_idx: int):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=padding_idx)\n",
    "        self.hidden_fc = nn.Linear(embed_dim, hidden_dim)\n",
    "        self.out_fc = nn.Linear(hidden_dim, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.padding_idx = padding_idx\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (batch, seq_len) of token ids (torch.long)\n",
    "        emb = self.embedding(x)  # (batch, seq_len, embed_dim)\n",
    "        mask = (x != self.padding_idx).unsqueeze(-1).to(emb.dtype)  # (batch, seq_len, 1)\n",
    "        summed = (emb * mask).sum(dim=1)  # (batch, embed_dim)\n",
    "        lengths = mask.sum(dim=1).clamp(min=1)  # (batch, 1)\n",
    "        mean_pooled = summed / lengths  # (batch, embed_dim)\n",
    "        h = self.relu(self.hidden_fc(mean_pooled))\n",
    "        return self.out_fc(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "405b8e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    }
   ],
   "source": [
    "# Dataset loading and subsampling\n",
    "ds = load_dataset(DATASET)\n",
    "train_split = ds['train']\n",
    "test_split = ds['test'] if 'test' in ds else ds['train']\n",
    "train_n = min(TRAIN_SAMPLES, len(train_split))\n",
    "test_n = min(TEST_SAMPLES, len(test_split))\n",
    "def stratified_select(dataset, n, label_field='label', seed=123):\n",
    "    labels = list(dataset[label_field])\n",
    "    total = len(labels)\n",
    "    if n >= total:\n",
    "        return dataset.shuffle(seed=seed)\n",
    "    classes = sorted(set(labels))\n",
    "    counts = {c: labels.count(c) for c in classes}\n",
    "    # Allocate per-class counts proportionally, with at least 1 when possible\n",
    "    alloc = {}\n",
    "    remaining = n\n",
    "    for c in classes[:-1]:\n",
    "        k = max(1, int(round(counts[c] / total * n)))\n",
    "        k = min(k, counts[c])\n",
    "        alloc[c] = k\n",
    "        remaining -= k\n",
    "    last = classes[-1]\n",
    "    alloc[last] = min(counts[last], max(0, remaining))\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    selected = []\n",
    "    for c in classes:\n",
    "        idxs = [i for i, lab in enumerate(labels) if lab == c]\n",
    "        random.shuffle(idxs)\n",
    "        take = alloc.get(c, 0)\n",
    "        selected.extend(idxs[:take])\n",
    "    # If short due to rounding, fill from remaining indices\n",
    "    if len(selected) < n:\n",
    "        remaining_idxs = [i for i in range(total) if i not in selected]\n",
    "        random.shuffle(remaining_idxs)\n",
    "        selected.extend(remaining_idxs[:(n - len(selected))])\n",
    "    random.shuffle(selected)\n",
    "    return dataset.select(selected)\n",
    "# Apply stratified subsampling to train and test splits\n",
    "train_split = stratified_select(train_split, train_n, seed=123)\n",
    "test_split = stratified_select(test_split, test_n, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b23d656f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This two-parter was excellent - the best since the series returned. Sure bits of the story were pinched from previous films, but what TV shows don\\'t do that these days. What we got here was a cracking good sci-fi story. A great big (really scary) monster imprisoned at the base of a deep pit, some superb aliens in The Ood - the best \"new\" aliens the revived series has come up with, a set of basically sympathetic and believable human characters (complete with a couple of unnamed \"expendable\" security people in true Star Trek fashion), some large-scale philosophical themes (love, loyalty, faith, etc.), and some top-drawer special effects.<br /><br />I loved every minute of this.',\n",
       " \"Stan Laurel and Oliver Hardy had extensive (separate) film careers before they were eventually teamed. For many of Ollie's pre-Stan films, he was billed on screen as Babe Hardy ... and throughout his adult life, Hardy was known to his friends as 'Babe'. While touring postwar Britain with Laurel in a music-hall act for Bernard Delfont, Hardy gave an interview to journalist John McCabe in which he explained the origin of this nickname: early in his acting career, Hardy got a shave from a gay hairdresser who squeezed Hardy's plump cheeks (the ones on his face) and said 'Nice baby!' Hardy's workmates started crying him 'Babe', and the nickname stuck.<br /><br />Although much of Hardy's pre-Laurel work is very interesting -- notably his comedy roles in support of Larry Semon and the Chaplin imitator Billy West -- his teamwork with Billy Ruge (who?) in a series of low-budget shorts for the Vim Comedy Film Company is very dire indeed. Hardy and Ruge were given the screen names Plump and Runt: names which are unpleasant in their own right, but made worse because Ruge (although shorter than Hardy) isn't especially a runt. Seen here, Hardy looks much as he does in his early Hal Roach films with Laurel ... but without the spit curls and the fastidious little moustache.<br /><br />'One Too Many', an absolutely typical Plunt and Runt epic, is direly unfunny ... and its dreichness is made even more conspicuous by the fact that this film has exactly the same premise as 'That's My Wife', one of Laurel and Hardy's most hilarious films. Plump (Hardy) is the star boarder in a rooming-house run by a tall gawky landlady. Runt (Ruge) is the porter. Plump receives a letter from his wealthy uncle John, whose dosh he expects to inherit. His uncle is coming to see him and to meet Plump's wife and baby. There's only one problem: Plump hasn't got a wife and baby. He's been lying to his uncle in order to seem a family man. Now, of course, Plump expects Runt to find him a wife and baby on short notice. Of course, the results are disastrous. It would be nice if those disastrous results were funny, but they aren't. Most of the unfunny humour here is just empty slapstick, with characters settling their arguments by shoving each other into bathtubs.<br /><br />SPOILERS COMING. Vim director Will Louis (who?) shows no instinct for camera framing: the actress who plays the landlady is significantly taller than Hardy, and Louis consistently sets up his shots so that her head is out of frame. This could be funny if done on purpose, but it's merely inept. At one point in this bad comedy, an extremely tasteless gag is looming on the horizon as Runt approaches a black laundress. 'Surely they wouldn't stoop THAT low for a laugh,' I thought. But they do. Runt steals the woman's black infant and tries to fob this off as Plump's progeny.<br /><br />Somehow, Plump acquires an infant's cot, but he still hasn't got a baby. With Uncle John coming up the stairs, Plump conscripts Runt for babyhood. This gag might just possibly have worked with a midget, or even with a truly runt-sized actor such as Chester Conklin, but Billy Ruge is only slightly below average height. Ruge's impersonation of a baby is neither believable nor funny, and Uncle John would have to be a complete moron to fall for it. Amazingly, he does!<br /><br />The most notable aspect of 'One Too Many' is a brief appearance -- apparently her only-ever film appearance -- by Madelyn Saloshin, Oliver Hardy's first wife. The marriage was not a happy one, although Hardy's marital troubles never attained the epic proportions of Stan Laurel's. <br /><br />Only one thing in this movie impressed me. There is a very brief flashback sequence, with Hardy reminiscing about his seaside romance with a bathing beauty. In 1916, there was still not yet a standard film grammar for conveying flashbacks: the one shown here is done gracefully and simply. Too bad this movie has no other merits. 'One Too Many' is definitely one film too many on Oliver Hardy's CV, and I'll rate this movie just one point out of 10. Laurel and Hardy together are definitely much funnier than either of them separately.\",\n",
       " 'My scalp still smarts from the burning coals heaped on it when I vowed I love this film. Bring on the coals; I\\'ll walk over them as well to say again that I love \"Bend it Like Beckham.\" Granted, there\\'s a lot of \"in spite of\" in that confession. It\\'s a bit movie-of-the-week; the screenplay is on the paint-by-numbers side. And, most troublingly, the director\\'s commentary implies that in this film beauty can be found primarily amongst the white of skin.<br /><br />The film\\'s genius is not in what\\'s obvious to the Syd Field-doctored eye: character arcs, themes, construction. It\\'s in both the surface and what lurks deep beneath, but not in those layers of artistic topsoil that reviewers seem most often to scratch at. Powerful, sometimes semi-clad female bodies not simply on display but kicking the crap out of a football do a better job of naturalizing female strength and agility than Lara Croft or Zhang Ziyi will ever do. These are real bodies (Keira Knightley\\'s excepted) whose work is not to look great first and kick butt later. They are working bodies whose beauty is in their movement and self-determination. And, in my book, lead actress Parminder Nagra is one of the most gorgeous creatures ever captured on screen \\x96 not only because she can lay claim to that hackneyed adjective, \"luminous,\" but because her performance has an honesty and un-bookish intelligence that\\'s utterly compelling.<br /><br />The result is a film women can enjoy without feeling like they\\'re making a pact with the devil to do so. As in Chadha\\'s \"Bride and Prejudice,\" the relationships amongst women sizzle with a chemistry that can\\'t be neatly slotted into the stodgy, Sweet Valley High categories of \"best friends\" or \"sisters.\" Perhaps Chadha is even right in her commentary to disavow the film\\'s flirtation with lesbianism. \"Bend it Like Beckham\" has an electricity that can\\'t be reduced to the simple hetero/homosexual love triangle its conventionally structured script would suggest. The precise nature of its pleasure is, ultimately, a bit of a mystery \\x96 and is all the more seductive for it.<br /><br />Oh yes, and did I mention that it\\'s hilarious?',\n",
       " \"Featured in 1955's THE COBWEB is an all star cast ranging from silent screen veteran LILLIAN GISH to Actors Studio progeny SUSAN STRASBERG. Set at an exclusive psychiatric hospital, what is this movie about you wonder......high drama ? Doctor & patient relationships ? Shock therapy treatment ? No, this howler is about who exactly will get to pick the draperies for a psychiatric hospital ! You think I'm kidding ? You won't believe your eyes as you're watching this unbelievable storyline that was turned into a movie ! Progressive head shrink Dr. McIver (RICHARD WIDMARK) wants to have all of the hospital's patients involved in the design, selection and execution of the needed new draperies. McIver's wife played by marble mouthed GLORIA GRAHAM wants to get her 2 cents in on this monumental task too. So does long time staffer Miss Inch (LILLIAN GISH). Directed by VINCENT MINELLI, you kinda wonder if he really became this overly involved in minute detail because of his marriage to worry wart JUDY GARLAND. Talented actors like LAUREN BACALL, SUSAN STRASBERG, CHARLES BOYER, and JOHN KERR are wasted in this hokey story. What were they thinking ?\",\n",
       " \"A well put together entry in the serial killer genre that unfortunately gets mired down in its own pretentiousness to be really satisfying. Willem Dafoe is superb as a NYC detective trying to track down what appears to be a copycat using the same Renaissance art-related killing techniques used in a series of murders he solved years earlier. Scott Speedman is Dafoe's junior partner and they have pretty good chemistry (at least for a while). Other characters pop up to conveniently tie the two cases together. Clea Duval is the friend of an earlier victim and Peter Stormare is some sort of art broker/mentor to Dafoe...that's a bit hard to take, although Stormare is, of course, never dull. The film's ending is particularly disappointing. Look fast for Deborah Harry as Dafoe's less than forthcoming neighbor.\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_split['text'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b8ce6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2000/2000 [00:00<00:00, 6200.28 examples/s]\n",
      "Map: 100%|██████████| 256/256 [00:00<00:00, 3063.84 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenization and tensor conversion using torchtext (word-level)\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import vocab as torchtext_vocab\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "# Build vocabulary from training texts\n",
    "counter = Counter()\n",
    "for txt in train_split['text']:\n",
    "    counter.update(tokenizer(txt))\n",
    "specials = [\"<pad>\", \"<unk>\"]\n",
    "vocab = torchtext_vocab(counter, specials=specials)\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "pad_idx = vocab['<pad>']\n",
    "unk_idx = vocab['<unk>']\n",
    "vocab_size = len(vocab)\n",
    "def tok_batch(batch):\n",
    "    ids_batch = []\n",
    "    for text in batch['text']:\n",
    "        toks = tokenizer(text)\n",
    "        ids = [vocab[t] for t in toks][:MAX_LEN]  # truncate to MAX_LEN\n",
    "        ids_batch.append(ids)\n",
    "    return {'input_ids': ids_batch}\n",
    "train_tok = train_split.map(tok_batch, batched=True, remove_columns=[c for c in train_split.column_names if c != 'label'])\n",
    "test_tok = test_split.map(tok_batch, batched=True, remove_columns=[c for c in test_split.column_names if c != 'label'])\n",
    "def pad_id_lists(id_lists, max_len=MAX_LEN):\n",
    "    tensors = [torch.tensor(ids, dtype=torch.long)[:max_len] for ids in id_lists]\n",
    "    if len(tensors) == 0:\n",
    "        return torch.empty((0, max_len), dtype=torch.long)\n",
    "    padded = pad_sequence(tensors, batch_first=True, padding_value=pad_idx)\n",
    "    if padded.size(1) < max_len:\n",
    "        padded = torch.nn.functional.pad(padded, (0, max_len - padded.size(1)), value=pad_idx)\n",
    "    else:\n",
    "        padded = padded[:, :max_len]\n",
    "    return padded\n",
    "train_ids = pad_id_lists(train_tok['input_ids'], MAX_LEN)\n",
    "train_y = torch.tensor(train_tok['label'], dtype=torch.int64)\n",
    "test_ids = pad_id_lists(test_tok['input_ids'], MAX_LEN)\n",
    "test_y = torch.tensor(test_tok['label'], dtype=torch.int64)\n",
    "num_classes = int(train_y.max().item() + 1)\n",
    "input_dim = int(train_ids.shape[1])  # seq_len (MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b4181e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1 train_loss=0.6878 val_acc=0.62\n",
      "epoch=2 train_loss=0.6650 val_acc=0.605\n",
      "epoch=3 train_loss=0.6244 val_acc=0.68\n",
      "epoch=4 train_loss=0.5633 val_acc=0.715\n",
      "epoch=5 train_loss=0.4850 val_acc=0.75\n",
      "epoch=6 train_loss=0.3980 val_acc=0.705\n",
      "epoch=7 train_loss=0.3121 val_acc=0.7\n",
      "epoch=8 train_loss=0.2435 val_acc=0.715\n",
      "epoch=9 train_loss=0.1788 val_acc=0.715\n",
      "epoch=10 train_loss=0.1284 val_acc=0.725\n",
      "Early stopping after 10 epochs (no improvement for 5 epochs)\n"
     ]
    }
   ],
   "source": [
    "# Training with validation and early stopping\n",
    "model = EmbeddingMLP(vocab_size=vocab_size, embed_dim=HIDDEN_DIM, hidden_dim=HIDDEN_DIM, num_classes=num_classes, padding_idx=pad_idx).to(DEVICE)\n",
    "# Create train/val split from train_ids/train_y\n",
    "n_train_total = train_ids.shape[0]\n",
    "val_n = int(n_train_total * VAL_RATIO)\n",
    "if val_n > 0:\n",
    "    # Stratified split to balance classes in train/val\n",
    "    classes = torch.unique(train_y)\n",
    "    train_idx_list = []\n",
    "    val_idx_list = []\n",
    "    for c in classes:\n",
    "        idx_c = (train_y == c).nonzero(as_tuple=True)[0]\n",
    "        idx_c = idx_c[torch.randperm(idx_c.size(0))]\n",
    "        n_val_c = max(1, int(idx_c.size(0) * VAL_RATIO))\n",
    "        val_idx_list.append(idx_c[:n_val_c])\n",
    "        train_idx_list.append(idx_c[n_val_c:])\n",
    "    val_idx = torch.cat(val_idx_list) if len(val_idx_list) > 0 else torch.tensor([], dtype=torch.long)\n",
    "    train_idx = torch.cat(train_idx_list) if len(train_idx_list) > 0 else torch.tensor([], dtype=torch.long)\n",
    "    # Shuffle final indices\n",
    "    train_idx = train_idx[torch.randperm(train_idx.size(0))] if train_idx.numel() > 0 else train_idx\n",
    "    val_idx = val_idx[torch.randperm(val_idx.size(0))] if val_idx.numel() > 0 else val_idx\n",
    "    train_ds = TensorDataset(train_ids[train_idx], train_y[train_idx])\n",
    "    val_ds = TensorDataset(train_ids[val_idx], train_y[val_idx])\n",
    "else:\n",
    "    train_ds = TensorDataset(train_ids, train_y)\n",
    "    val_ds = None\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False) if val_ds is not None else None\n",
    "test_loader = DataLoader(TensorDataset(test_ids, test_y), batch_size=BATCH_SIZE, shuffle=False)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "best_val_acc = -1.0\n",
    "best_state = None\n",
    "epochs_no_improve = 0\n",
    "model.train()\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    running = 0.0\n",
    "    seen = 0\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(DEVICE)\n",
    "        yb = yb.to(DEVICE)\n",
    "        optim.zero_grad(set_to_none=True)\n",
    "        logits = model(xb)\n",
    "        loss = loss_fn(logits, yb)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        running += float(loss.item()) * int(yb.numel())\n",
    "        seen += int(yb.numel())\n",
    "    # Validation\n",
    "    val_acc = None\n",
    "    if val_loader is not None:\n",
    "        model.eval()\n",
    "        total_v = 0\n",
    "        correct_v = 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb = xb.to(DEVICE)\n",
    "                yb = yb.to(DEVICE)\n",
    "                logits = model(xb)\n",
    "                pred = logits.argmax(dim=-1)\n",
    "                correct_v += int((pred == yb).sum().item())\n",
    "                total_v += int(yb.numel())\n",
    "        val_acc = correct_v / max(total_v, 1)\n",
    "    train_loss = running / max(seen, 1)\n",
    "    # Check improvement on validation (or test if no val set)\n",
    "    monitor_acc = val_acc if val_acc is not None else 0.0\n",
    "    improved = (monitor_acc > best_val_acc)\n",
    "    if improved:\n",
    "        best_val_acc = monitor_acc\n",
    "        # save CPU copy of state dict\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "    print(f'epoch={epoch} train_loss={train_loss:.4f} val_acc={val_acc if val_acc is not None else \"N/A\"}')\n",
    "    model.train()\n",
    "    if epochs_no_improve >= PATIENCE:\n",
    "        print(f'Early stopping after {epoch} epochs (no improvement for {PATIENCE} epochs)')\n",
    "        break\n",
    "# restore best model state if available\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d62d5215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_test_acc=0.6523\n"
     ]
    }
   ],
   "source": [
    "# Final testing/evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(DEVICE)\n",
    "        yb = yb.to(DEVICE)\n",
    "        logits = model(xb)\n",
    "        pred = logits.argmax(dim=-1)\n",
    "        correct += int((pred == yb).sum().item())\n",
    "        total += int(yb.numel())\n",
    "    print(f'final_test_acc={correct/max(total,1):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8c776b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2000/2000 [00:00<00:00, 6327.46 examples/s]\n",
      "Map: 100%|██████████| 256/256 [00:00<00:00, 5978.45 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config={'lr': 0.001, 'weight_decay': 0.0, 'dropout': 0.3, 'num_layers': 3, 'hidden_dim': 64, 'max_len': 64, 'padding': True} best_val=0.6800 test_acc=0.7305 elapsed=3.7s\n",
      "config={'lr': 0.0005, 'weight_decay': 0.001, 'dropout': 0.0, 'num_layers': 2, 'hidden_dim': 128, 'max_len': 64, 'padding': True} best_val=0.6050 test_acc=0.6328 elapsed=10.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2000/2000 [00:00<00:00, 6549.90 examples/s]\n",
      "Map: 100%|██████████| 256/256 [00:00<00:00, 5965.13 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config={'lr': 0.0005, 'weight_decay': 0.001, 'dropout': 0.5, 'num_layers': 1, 'hidden_dim': 128, 'max_len': 128, 'padding': True} best_val=0.6600 test_acc=0.6680 elapsed=17.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2000/2000 [00:00<00:00, 6731.27 examples/s]\n",
      "Map: 100%|██████████| 256/256 [00:00<00:00, 5994.54 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config={'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.3, 'num_layers': 1, 'hidden_dim': 128, 'max_len': 32, 'padding': True} best_val=0.6700 test_acc=0.6211 elapsed=24.1s\n",
      "config={'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.0, 'num_layers': 2, 'hidden_dim': 256, 'max_len': 128, 'padding': 'max_length'} best_val=0.6800 test_acc=0.7344 elapsed=38.3s\n",
      "config={'lr': 0.001, 'weight_decay': 0.0, 'dropout': 0.5, 'num_layers': 4, 'hidden_dim': 64, 'max_len': 128, 'padding': True} best_val=0.7800 test_acc=0.7773 elapsed=41.9s\n",
      "config={'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.2, 'num_layers': 3, 'hidden_dim': 256, 'max_len': 64, 'padding': 'max_length'} best_val=0.6700 test_acc=0.6758 elapsed=59.6s\n",
      "config={'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.0, 'num_layers': 2, 'hidden_dim': 256, 'max_len': 64, 'padding': True} best_val=0.7600 test_acc=0.7031 elapsed=71.2s\n",
      "config={'lr': 0.0005, 'weight_decay': 0.0001, 'dropout': 0.3, 'num_layers': 3, 'hidden_dim': 256, 'max_len': 128, 'padding': 'max_length'} best_val=0.7050 test_acc=0.7344 elapsed=89.6s\n",
      "config={'lr': 0.0005, 'weight_decay': 0.0001, 'dropout': 0.3, 'num_layers': 3, 'hidden_dim': 64, 'max_len': 32, 'padding': 'max_length'} best_val=0.6050 test_acc=0.6133 elapsed=93.2s\n",
      "config={'lr': 0.01, 'weight_decay': 0.0, 'dropout': 0.2, 'num_layers': 3, 'hidden_dim': 128, 'max_len': 64, 'padding': True} best_val=0.7550 test_acc=0.6914 elapsed=97.4s\n",
      "config={'lr': 0.0005, 'weight_decay': 0.0001, 'dropout': 0.5, 'num_layers': 3, 'hidden_dim': 64, 'max_len': 128, 'padding': 'max_length'} best_val=0.7000 test_acc=0.6992 elapsed=101.4s\n",
      "config={'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.5, 'num_layers': 1, 'hidden_dim': 64, 'max_len': 32, 'padding': True} best_val=0.6700 test_acc=0.6328 elapsed=103.6s\n",
      "config={'lr': 0.0005, 'weight_decay': 0.0001, 'dropout': 0.2, 'num_layers': 2, 'hidden_dim': 64, 'max_len': 32, 'padding': True} best_val=0.6050 test_acc=0.6133 elapsed=107.3s\n",
      "config={'lr': 0.0005, 'weight_decay': 0.0001, 'dropout': 0.5, 'num_layers': 1, 'hidden_dim': 128, 'max_len': 64, 'padding': True} best_val=0.6250 test_acc=0.6406 elapsed=113.2s\n",
      "config={'lr': 0.0005, 'weight_decay': 0.0001, 'dropout': 0.3, 'num_layers': 1, 'hidden_dim': 256, 'max_len': 64, 'padding': True} best_val=0.6550 test_acc=0.6484 elapsed=123.7s\n",
      "config={'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.2, 'num_layers': 4, 'hidden_dim': 256, 'max_len': 32, 'padding': True} best_val=0.6850 test_acc=0.6758 elapsed=137.2s\n",
      "config={'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.0, 'num_layers': 3, 'hidden_dim': 128, 'max_len': 32, 'padding': True} best_val=0.6700 test_acc=0.6211 elapsed=141.9s\n",
      "config={'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.3, 'num_layers': 3, 'hidden_dim': 256, 'max_len': 64, 'padding': 'max_length'} best_val=0.6400 test_acc=0.6094 elapsed=149.4s\n",
      "config={'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.3, 'num_layers': 4, 'hidden_dim': 128, 'max_len': 128, 'padding': 'max_length'} best_val=0.7850 test_acc=0.7344 elapsed=153.0s\n",
      "\n",
      "Top results:\n",
      "{'config': {'lr': 0.001, 'weight_decay': 0.0, 'dropout': 0.5, 'num_layers': 4, 'hidden_dim': 64, 'max_len': 128, 'padding': True}, 'best_val': 0.78, 'test_acc': 0.77734375, 'elapsed_s': 41.87577748298645}\n",
      "{'config': {'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.0, 'num_layers': 2, 'hidden_dim': 256, 'max_len': 128, 'padding': 'max_length'}, 'best_val': 0.68, 'test_acc': 0.734375, 'elapsed_s': 38.29011678695679}\n",
      "{'config': {'lr': 0.0005, 'weight_decay': 0.0001, 'dropout': 0.3, 'num_layers': 3, 'hidden_dim': 256, 'max_len': 128, 'padding': 'max_length'}, 'best_val': 0.705, 'test_acc': 0.734375, 'elapsed_s': 89.60307741165161}\n",
      "{'config': {'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.3, 'num_layers': 4, 'hidden_dim': 128, 'max_len': 128, 'padding': 'max_length'}, 'best_val': 0.785, 'test_acc': 0.734375, 'elapsed_s': 153.04590678215027}\n",
      "{'config': {'lr': 0.001, 'weight_decay': 0.0, 'dropout': 0.3, 'num_layers': 3, 'hidden_dim': 64, 'max_len': 64, 'padding': True}, 'best_val': 0.68, 'test_acc': 0.73046875, 'elapsed_s': 3.691236734390259}\n",
      "Saved sweep_results.json\n"
     ]
    }
   ],
   "source": [
    "# Expanded hyperparameter/configuration sweep (sampled from full grid)\n",
    "import itertools, random, json, time\n",
    "# parameter grids\n",
    "lrs = [1e-2, 5e-3, 1e-3, 5e-4]\n",
    "wds = [0.0, 1e-4, 1e-3]\n",
    "dropouts = [0.0, 0.2, 0.3, 0.5]\n",
    "num_layers_list = [1, 2, 3, 4]\n",
    "hidden_dims = [64, 128, 256]\n",
    "max_lens = [32, 64, 128]\n",
    "padding_modes = [True, 'max_length']\n",
    "# sampling configuration\n",
    "FULL_GRID = list(itertools.product(lrs, wds, dropouts, num_layers_list, hidden_dims, max_lens, padding_modes))\n",
    "random.seed(123)\n",
    "random.shuffle(FULL_GRID)\n",
    "N_CONFIGS = min(20, len(FULL_GRID))  # pick a sampled subset to keep runtime reasonable\n",
    "SELECTED = FULL_GRID[:N_CONFIGS]\n",
    "EPOCHS_SWEEP = 20\n",
    "PATIENCE_SWEEP = 5\n",
    "results = []\n",
    "\n",
    "def prepare_tensors_for_config(max_len, padding_mode):\n",
    "    # re-tokenize train/test splits for this config (word-level using existing vocab)\n",
    "    def tok_batch_local(batch):\n",
    "        ids_batch = []\n",
    "        for text in batch['text']:\n",
    "            toks = tokenizer(text)\n",
    "            ids = [vocab[t] for t in toks][:max_len]\n",
    "            ids_batch.append(ids)\n",
    "        return {'input_ids': ids_batch}\n",
    "    tr_tok = train_split.map(tok_batch_local, batched=True, remove_columns=[c for c in train_split.column_names if c != 'label'])\n",
    "    te_tok = test_split.map(tok_batch_local, batched=True, remove_columns=[c for c in test_split.column_names if c != 'label'])\n",
    "    def pad_id_lists_local(id_lists, max_len=max_len):\n",
    "        tensors = [torch.tensor(ids, dtype=torch.long)[:max_len] for ids in id_lists]\n",
    "        if len(tensors) == 0:\n",
    "            return torch.empty((0, max_len), dtype=torch.long)\n",
    "        padded = pad_sequence(tensors, batch_first=True, padding_value=pad_idx)\n",
    "        if padded.size(1) < max_len:\n",
    "            padded = torch.nn.functional.pad(padded, (0, max_len - padded.size(1)), value=pad_idx)\n",
    "        else:\n",
    "            padded = padded[:, :max_len]\n",
    "        return padded\n",
    "    tr_ids = pad_id_lists_local(tr_tok['input_ids'])\n",
    "    te_ids = pad_id_lists_local(te_tok['input_ids'])\n",
    "    tr_y = torch.tensor(tr_tok['label'], dtype=torch.int64)\n",
    "    te_y = torch.tensor(te_tok['label'], dtype=torch.int64)\n",
    "    return tr_ids, tr_y, te_ids, te_y\n",
    "\n",
    "start_time = time.time()\n",
    "for (lr, wd, drop, nlayers, hdim, mlen, pad_mode) in SELECTED:\n",
    "    torch.manual_seed(123)\n",
    "    # prepare tensors for this config\n",
    "    tr_x_cfg, tr_y_cfg, te_x_cfg, te_y_cfg = prepare_tensors_for_config(mlen, pad_mode)\n",
    "    # stratified train/val split (same logic as above)\n",
    "    n_train_total = tr_x_cfg.shape[0]\n",
    "    val_n = int(n_train_total * VAL_RATIO)\n",
    "    if val_n > 0:\n",
    "        classes = torch.unique(tr_y_cfg)\n",
    "        train_idx_list = []\n",
    "        val_idx_list = []\n",
    "        for c in classes:\n",
    "            idx_c = (tr_y_cfg == c).nonzero(as_tuple=True)[0]\n",
    "            idx_c = idx_c[torch.randperm(idx_c.size(0))]\n",
    "            n_val_c = max(1, int(idx_c.size(0) * VAL_RATIO))\n",
    "            val_idx_list.append(idx_c[:n_val_c])\n",
    "            train_idx_list.append(idx_c[n_val_c:])\n",
    "        val_idx = torch.cat(val_idx_list) if len(val_idx_list) > 0 else torch.tensor([], dtype=torch.long)\n",
    "        train_idx = torch.cat(train_idx_list) if len(train_idx_list) > 0 else torch.tensor([], dtype=torch.long)\n",
    "        train_idx = train_idx[torch.randperm(train_idx.size(0))] if train_idx.numel() > 0 else train_idx\n",
    "        val_idx = val_idx[torch.randperm(val_idx.size(0))] if val_idx.numel() > 0 else val_idx\n",
    "        train_ds = TensorDataset(tr_x_cfg[train_idx], tr_y_cfg[train_idx])\n",
    "        val_ds = TensorDataset(tr_x_cfg[val_idx], tr_y_cfg[val_idx])\n",
    "    else:\n",
    "        train_ds = TensorDataset(tr_x_cfg, tr_y_cfg)\n",
    "        val_ds = None\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False) if val_ds is not None else None\n",
    "    # build model for config (embedding-based)\n",
    "    model_s = EmbeddingMLP(vocab_size=vocab_size, embed_dim=hdim, hidden_dim=hdim, num_classes=num_classes, padding_idx=pad_idx).to(DEVICE)\n",
    "    optim_s = torch.optim.Adam(model_s.parameters(), lr=lr, weight_decay=wd)\n",
    "    loss_fn_s = nn.CrossEntropyLoss()\n",
    "    best_val = -1.0\n",
    "    best_state = None\n",
    "    epochs_no_improve = 0\n",
    "    for epoch in range(1, EPOCHS_SWEEP+1):\n",
    "        model_s.train()\n",
    "        running = 0.0\n",
    "        seen = 0\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            yb = yb.to(DEVICE)\n",
    "            optim_s.zero_grad(set_to_none=True)\n",
    "            logits = model_s(xb)\n",
    "            loss = loss_fn_s(logits, yb)\n",
    "            loss.backward()\n",
    "            optim_s.step()\n",
    "            running += float(loss.item()) * int(yb.numel())\n",
    "            seen += int(yb.numel())\n",
    "        # validation\n",
    "        val_acc = None\n",
    "        if val_loader is not None:\n",
    "            model_s.eval()\n",
    "            total_v = 0\n",
    "            correct_v = 0\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in val_loader:\n",
    "                    xb = xb.to(DEVICE)\n",
    "                    yb = yb.to(DEVICE)\n",
    "                    pred = model_s(xb).argmax(dim=-1)\n",
    "                    correct_v += int((pred == yb).sum().item())\n",
    "                    total_v += int(yb.numel())\n",
    "            val_acc = correct_v / max(total_v, 1)\n",
    "        train_loss = running / max(seen, 1)\n",
    "        monitor_acc = val_acc if val_acc is not None else 0.0\n",
    "        if monitor_acc > best_val:\n",
    "            best_val = monitor_acc\n",
    "            best_state = {k: v.cpu().clone() for k, v in model_s.state_dict().items()}\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        if epochs_no_improve >= PATIENCE_SWEEP:\n",
    "            break\n",
    "    if best_state is not None:\n",
    "        model_s.load_state_dict(best_state)\n",
    "    # test evaluation\n",
    "    model_s.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in DataLoader(TensorDataset(te_x_cfg, te_y_cfg), batch_size=BATCH_SIZE):\n",
    "            xb = xb.to(DEVICE)\n",
    "            yb = yb.to(DEVICE)\n",
    "            pred = model_s(xb).argmax(dim=-1)\n",
    "            correct += int((pred == yb).sum().item())\n",
    "            total += int(yb.numel())\n",
    "    test_acc = correct / max(total, 1)\n",
    "    elapsed = time.time() - start_time\n",
    "    cfg = dict(lr=lr, weight_decay=wd, dropout=drop, num_layers=nlayers, hidden_dim=hdim, max_len=mlen, padding=pad_mode)\n",
    "    results.append({'config': cfg, 'best_val': best_val, 'test_acc': test_acc, 'elapsed_s': elapsed})\n",
    "    print(f\"config={cfg} best_val={best_val:.4f} test_acc={test_acc:.4f} elapsed={elapsed:.1f}s\")\n",
    "# summarize top results by test accuracy\n",
    "results_sorted = sorted(results, key=lambda x: x['test_acc'], reverse=True)\n",
    "print('\\nTop results:')\n",
    "for r in results_sorted[:5]:\n",
    "    print(r)\n",
    "# persist results\n",
    "with open('sweep_results.json', 'w') as fh:\n",
    "    json.dump(results_sorted, fh, indent=2)\n",
    "print('Saved sweep_results.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055eab6d",
   "metadata": {},
   "source": [
    "## Approximate experiment: collapse embeddings to a single scalar per token\n",
    "This section implements the approximate approach (collapse each token's embedding to a single scalar) so the model can be treated as a scalar-token MLP.\n",
    "It trains a small model that learns a projection from embedding -> scalar per token, then feeds the resulting per-token scalars (shape `seq_len`) to a standard MLP.\n",
    "This lets you compare performance quickly while keeping compatibility with the existing `feedforward.cu` input expectations (one scalar per token)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0791931e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1 train_loss=0.6942 test_acc=0.4883\n",
      "epoch=2 train_loss=0.6678 test_acc=0.4570\n",
      "epoch=3 train_loss=0.6334 test_acc=0.5078\n",
      "epoch=4 train_loss=0.5779 test_acc=0.5039\n",
      "epoch=5 train_loss=0.5126 test_acc=0.5000\n",
      "epoch=6 train_loss=0.4345 test_acc=0.5156\n",
      "epoch=7 train_loss=0.3571 test_acc=0.5156\n",
      "epoch=8 train_loss=0.2771 test_acc=0.5195\n",
      "epoch=9 train_loss=0.2055 test_acc=0.5273\n",
      "epoch=10 train_loss=0.1436 test_acc=0.5430\n",
      "final_collapsed_test_acc=0.5430\n"
     ]
    }
   ],
   "source": [
    "# Collapsed-embedding model: learnable projection from embed_dim -> 1 per token, then MLP on seq_len scalars\n",
    "import torch.nn.functional as F\n",
    "class CollapsedEmbeddingMLP(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, seq_len, hidden_dim, num_classes, padding_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=padding_idx)\n",
    "        # project each token embedding to a single scalar (learned)\n",
    "        self.proj = nn.Linear(embed_dim, 1, bias=True)\n",
    "        # MLP that consumes seq_len scalar features\n",
    "        self.hidden_fc = nn.Linear(seq_len, hidden_dim)\n",
    "        self.out_fc = nn.Linear(hidden_dim, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.padding_idx = padding_idx\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len) long token ids\n",
    "        emb = self.embedding(x)  # (batch, seq_len, embed_dim)\n",
    "        mask = (x != self.padding_idx).unsqueeze(-1).to(emb.dtype)  # (batch, seq_len, 1)\n",
    "        emb = emb * mask  # zero-out pad embeddings\n",
    "        scalars = self.proj(emb).squeeze(-1)  # (batch, seq_len)\n",
    "        # ensure pad positions are zero\n",
    "        scalars = scalars * mask.squeeze(-1)\n",
    "        h = self.relu(self.hidden_fc(scalars))\n",
    "        return self.out_fc(h)\n",
    "\n",
    "# Instantiate model (uses previously-defined variables: vocab_size, HIDDEN_DIM, input_dim, num_classes, pad_idx, DEVICE)\n",
    "seq_len = input_dim\n",
    "model_collapsed = CollapsedEmbeddingMLP(vocab_size=vocab_size, embed_dim=HIDDEN_DIM, seq_len=seq_len, hidden_dim=HIDDEN_DIM, num_classes=num_classes, padding_idx=pad_idx).to(DEVICE)\n",
    "# Prepare simple dataloaders (use full train_ids/train_y and test_ids/test_y)\n",
    "train_ds_coll = TensorDataset(train_ids, train_y)\n",
    "train_loader_coll = DataLoader(train_ds_coll, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader_coll = DataLoader(TensorDataset(test_ids, test_y), batch_size=BATCH_SIZE, shuffle=False)\n",
    "optim_c = torch.optim.Adam(model_collapsed.parameters(), lr=1e-3)\n",
    "loss_fn_c = nn.CrossEntropyLoss()\n",
    "# Quick training loop (small number of epochs for experiment)\n",
    "EPOCHS_COLLAPSE = 10\n",
    "for epoch in range(1, EPOCHS_COLLAPSE+1):\n",
    "    model_collapsed.train()\n",
    "    running = 0.0\n",
    "    seen = 0\n",
    "    for xb, yb in train_loader_coll:\n",
    "        xb = xb.to(DEVICE)\n",
    "        yb = yb.to(DEVICE)\n",
    "        optim_c.zero_grad(set_to_none=True)\n",
    "        logits = model_collapsed(xb)\n",
    "        loss = loss_fn_c(logits, yb)\n",
    "        loss.backward()\n",
    "        optim_c.step()\n",
    "        running += float(loss.item()) * int(yb.numel())\n",
    "        seen += int(yb.numel())\n",
    "    train_loss = running / max(seen, 1)\n",
    "    # quick val on test set for monitoring\n",
    "    model_collapsed.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader_coll:\n",
    "            xb = xb.to(DEVICE)\n",
    "            yb = yb.to(DEVICE)\n",
    "            pred = model_collapsed(xb).argmax(dim=-1)\n",
    "            correct += int((pred == yb).sum().item())\n",
    "            total += int(yb.numel())\n",
    "    test_acc = correct / max(total, 1)\n",
    "    print(f'epoch={epoch} train_loss={train_loss:.4f} test_acc={test_acc:.4f}')\n",
    "\n",
    "# Final test evaluation\n",
    "model_collapsed.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for xb, yb in test_loader_coll:\n",
    "        xb = xb.to(DEVICE)\n",
    "        yb = yb.to(DEVICE)\n",
    "        pred = model_collapsed(xb).argmax(dim=-1)\n",
    "        correct += int((pred == yb).sum().item())\n",
    "        total += int(yb.numel())\n",
    "    print(f'final_collapsed_test_acc={correct/max(total,1):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
